# Cost and Latency

This document describes the cost and latency characteristics of the workflows implemented in this repository.

The goal is not to provide exact dollar figures. The goal is to identify **what drives cost and latency**, how those factors scale, and where tradeoffs appear as orchestration complexity increases.

Variant 1 serves as the baseline.

---

## Cost model overview

In all variants, cost is driven primarily by:

- Number of model calls
- Size of prompts sent to the model
- Size of responses generated by the model
- Optional downstream steps (for example short-form generation)

Variant 1 tracks call count explicitly and stores prompt traces to enable later cost analysis.

---

## Variant 1: baseline cost characteristics

### Model calls per run

For a run with:
- N topics
- S short-form platforms enabled

Variant 1 makes approximately:

- N calls for per-topic research
- 1 call for synthesis
- S calls for short-form generation (optional)

Total calls:


This is recorded in `run_manifest.json` as `call_count`.

---

### Prompt and response size drivers

Prompt size increases with:
- Topic question length
- Constraint verbosity
- Number of topics (indirectly, via synthesis prompt)

Response size increases with:
- Model verbosity
- Topic complexity
- Temperature settings

Variant 1 does not currently enforce output length or token limits.

---

### Cost visibility limitations

Variant 1 intentionally does not:
- Track token usage
- Estimate per-call or per-run cost
- Enforce budgets

This is a deliberate choice to avoid premature optimization and provider coupling.

Prompt traces are stored so token usage can be retroactively estimated if needed.

---

## Latency model overview

Latency is influenced by:

- Sequential execution
- Model response time per call
- Network latency
- Output size

Variant 1 executes synchronously and sequentially.

---

## Variant 1: baseline latency characteristics

### Execution pattern

Variant 1 follows this sequence:

1. Topic 1 research
2. Topic 2 research
3. â€¦
4. Topic N research
5. Synthesis
6. Short-form generation (optional, sequential per platform)

There is no parallelism.

---

### Latency scaling behavior

For N topics and S short-form platforms:

- Latency scales approximately linearly with N
- Short-form generation adds incremental latency per platform
- Synthesis latency grows with the size of aggregated topic notes

Total runtime increases predictably as inputs increase.

---

### Latency transparency

Variant 1 makes latency observable by:
- Writing artifacts incrementally
- Allowing inspection of partially completed runs
- Recording call count in the manifest

Variant 1 does not currently:
- Record timestamps per step
- Measure per-call latency
- Enforce timeouts beyond provider defaults

---

## Tradeoffs exposed by Variant 1

Variant 1 intentionally favors:

- Predictability over throughput
- Simplicity over concurrency
- Observability over performance

This makes Variant 1 unsuitable for high-throughput workloads, but ideal as a reference implementation.

---

## Expected changes in later variants

Later variants are expected to introduce:

### Cost-related changes
- Tool reuse and caching
- Fewer redundant calls
- Structured outputs that reduce response size
- Optional cost guards and budgets

### Latency-related changes
- Parallel topic processing
- Asynchronous orchestration
- Partial retries instead of full reruns

Each of these changes improves performance but increases system complexity and reduces transparency.

---

## Why cost and latency are documented early

Cost and latency are often treated as operational concerns added late in development.

This repository documents them early because:
- Cost is a form of system behavior
- Latency influences failure handling
- Orchestration abstractions often hide performance tradeoffs

By documenting these characteristics in Variant 1, later improvements can be evaluated against a known baseline.

---

## What is intentionally missing

Variant 1 does not include:
- Token accounting
- Provider-specific pricing logic
- SLA enforcement
- Adaptive throttling

These features are postponed to avoid obscuring baseline behavior.

---

## Summary

Variant 1 establishes a transparent, predictable cost and latency baseline.

Later variants will move these characteristics in different directions. Those changes are intentional and should be evaluated as tradeoffs, not automatic improvements.
